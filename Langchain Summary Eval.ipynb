{"cells":[{"cell_type":"markdown","id":"6f83d733-dfee-470d-9638-63032c95ee84","metadata":{"id":"6f83d733-dfee-470d-9638-63032c95ee84"},"source":["## Model Setup"]},{"cell_type":"code","execution_count":null,"id":"8d1742a7-f872-4ec9-83aa-3f37ea78babe","metadata":{"id":"8d1742a7-f872-4ec9-83aa-3f37ea78babe","outputId":"4260cf96-83cd-4e6f-975e-2e047b705d17"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.84s/it]\n"]}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"./models/Llama2-32K/\")\n","model = AutoModelForCausalLM.from_pretrained(\"./models/Llama2-32K/\",\n","                                            #trust_remote_code = True,\n","                                             load_in_8bit = True,\n","                                             device_map=\"auto\",\n","                                             torch_dtype=torch.float16,\n","                                            )\n","from transformers import pipeline\n","from langchain.llms import HuggingFacePipeline\n","import torch\n","\n","pipe = pipeline(\n","    task=\"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    max_new_tokens=512,\n","    temperature=0.0,\n","    top_p=0.95,\n","    repetition_penalty=1.15,\n",")\n","\n","local_llm = HuggingFacePipeline(pipeline=pipe)"]},{"cell_type":"markdown","id":"6339054b-3775-4f16-96e4-a4481f65014d","metadata":{"id":"6339054b-3775-4f16-96e4-a4481f65014d"},"source":["## Summary Evaluation"]},{"cell_type":"code","execution_count":null,"id":"6d65cadb-4b28-4e23-bc22-514bdc22a565","metadata":{"id":"6d65cadb-4b28-4e23-bc22-514bdc22a565"},"outputs":[],"source":["%%capture\n","from datasets import load_dataset\n","# TEXT | SUMMARY | TITLE\n","billsum = load_dataset(\"billsum\", split=\"ca_test\")  # testi di lunghezza max = 6000 tokens"]},{"cell_type":"code","execution_count":null,"id":"d10788a9-4b01-4dd1-9a45-5418207dc6a6","metadata":{"id":"d10788a9-4b01-4dd1-9a45-5418207dc6a6"},"outputs":[],"source":["dataset = billsum.select(range(0,15))"]},{"cell_type":"code","execution_count":null,"id":"6da903b2-e174-47f0-88ab-9b63462f28ca","metadata":{"id":"6da903b2-e174-47f0-88ab-9b63462f28ca","outputId":"2bdf2769-a3d3-4ca8-a8ec-739e3bcd5b7b"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['text', 'summary', 'title'],\n","    num_rows: 15\n","})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":null,"id":"52c5d47f-1f44-4061-bc85-19bf25ecca74","metadata":{"id":"52c5d47f-1f44-4061-bc85-19bf25ecca74"},"outputs":[],"source":["# Splitto ogni cella contenente il testo in chunks\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.docstore.document import Document\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n","\n","docs = []\n","for d in dataset:\n","  text = d[\"text\"]\n","  texts = text_splitter.split_text(text)\n","  doc = [Document(page_content=t) for t in texts]\n","  docs.append(doc)"]},{"cell_type":"code","execution_count":null,"id":"6a24536c-8cc8-4481-b4f9-f66d84f349aa","metadata":{"id":"6a24536c-8cc8-4481-b4f9-f66d84f349aa","outputId":"8ed47cf6-ecbb-45d1-acc9-49eb72137caa"},"outputs":[{"data":{"text/plain":["667"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Controllo la lunghezza massima in token dei chunk ottenuti\n","max=0\n","for d in docs:\n","    for dd in d:\n","        text=dd.page_content\n","        length = len(tokenizer.tokenize(text))\n","        if length>max:  max=length\n","max"]},{"cell_type":"code","execution_count":null,"id":"d01583bb-8a59-4c74-8977-f4600440cbb4","metadata":{"id":"d01583bb-8a59-4c74-8977-f4600440cbb4"},"outputs":[],"source":["from langchain.chains.summarize import load_summarize_chain\n","\n","chain = load_summarize_chain(local_llm,\n","                             chain_type=\"map_reduce\", # altrimenti \"stuff\" per passare tutto il testo insieme\n","                            )"]},{"cell_type":"code","execution_count":null,"id":"96a94e9d-c7a6-4d11-ac08-9fa2ff4d9445","metadata":{"id":"96a94e9d-c7a6-4d11-ac08-9fa2ff4d9445","outputId":"e3ef84d7-9b07-4799-eadd-f8fdddf2bb5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 22min 15s, sys: 0 ns, total: 22min 15s\n","Wall time: 22min 21s\n"]}],"source":["%%time\n","# Eseguo la chain sui chunk ottenuti\n","llm_summaries = []\n","\n","for d in docs:\n","    summary = chain.run(d)\n","    llm_summaries.append(summary)"]},{"cell_type":"code","execution_count":null,"id":"7ce22019-b543-4498-a9ec-0f81cf7c0cb1","metadata":{"id":"7ce22019-b543-4498-a9ec-0f81cf7c0cb1"},"outputs":[],"source":["%%time\n","# SOLO PER LLM CON INPUT WINDOW GRANDI, eseugo la chain sui testi originali\n","from langchain.docstore.document import Document\n","llm_summaries = []\n","\n","for d in dataset:\n","    text = d[\"text\"]\n","    doc = [Document(page_content=text)]\n","    summary = chain.run(doc)\n","    llm_summaries.append(summary)"]},{"cell_type":"markdown","source":[" ## Evaluation con Rouge Score"],"metadata":{"id":"XRUN26z8Yapj"},"id":"XRUN26z8Yapj"},{"cell_type":"code","execution_count":null,"id":"ac3f42e9-0deb-421b-bb7b-7bc180f46405","metadata":{"id":"ac3f42e9-0deb-421b-bb7b-7bc180f46405"},"outputs":[],"source":["dataset = dataset.add_column(\"new_summ\", llm_summaries)"]},{"cell_type":"code","execution_count":null,"id":"1eb9af24-8723-4f1c-accb-8cc53b704c8b","metadata":{"id":"1eb9af24-8723-4f1c-accb-8cc53b704c8b"},"outputs":[],"source":["import evaluate\n","import numpy as np\n","\n","rouge = evaluate.load(\"rouge\")\n","\n","def compute_metrics(dataset):\n","    predictions = dataset[\"new_summ\"]\n","    labels = dataset[\"summary\"]\n","\n","    result = rouge.compute(predictions=predictions, references=labels, use_stemmer=True)\n","\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","\n","    return {k: round(v, 4) for k, v in result.items()}"]},{"cell_type":"code","execution_count":null,"id":"586e6ec3-b9ae-44ba-8cce-a05ebcc89b1e","metadata":{"id":"586e6ec3-b9ae-44ba-8cce-a05ebcc89b1e","outputId":"3fb21e44-f5be-4353-b210-5e03a7d06a64"},"outputs":[{"data":{"text/plain":["{'rouge1': 0.3107,\n"," 'rouge2': 0.0944,\n"," 'rougeL': 0.1619,\n"," 'rougeLsum': 0.2406,\n"," 'gen_len': 1.0}"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["compute_metrics(dataset)"]},{"cell_type":"code","execution_count":null,"id":"434e2cee-fe91-4be0-bda4-bcef15485c3c","metadata":{"id":"434e2cee-fe91-4be0-bda4-bcef15485c3c"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}