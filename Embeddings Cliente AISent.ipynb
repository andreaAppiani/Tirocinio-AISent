{"cells":[{"cell_type":"markdown","source":["Testo vari modelli di Embeddings sulle frasi date dal cliente"],"metadata":{"id":"4Ew4fbPuhF2j"},"id":"4Ew4fbPuhF2j"},{"cell_type":"code","execution_count":null,"id":"4c37eeb0-480f-4d49-bbb6-895bb12364b5","metadata":{"id":"4c37eeb0-480f-4d49-bbb6-895bb12364b5"},"outputs":[],"source":["import pandas as pd\n","from langchain.docstore.document import Document\n","\n","data = pd.read_csv(\"./Source_documents/sample_semantic_similarity.csv\")\n","\n","# Converto le righe in docs per creare Vector Databases da cui fare retrieval\n","# e quindi testare gli embeddings delle righe\n","\n","docs = [Document(page_content=row[\"sentence\"],\n","                 metadata={'row':index+1, \"topic\":row[\"topic\"]})\n","        for index, row in data.iterrows()]"]},{"cell_type":"markdown","id":"00cdf485-ac38-4e3d-9e61-804046c8b9a8","metadata":{"id":"00cdf485-ac38-4e3d-9e61-804046c8b9a8"},"source":["## Instructor Embeddings"]},{"cell_type":"code","execution_count":null,"id":"63ae26a0-5852-48be-b147-508862ecff35","metadata":{"id":"63ae26a0-5852-48be-b147-508862ecff35"},"outputs":[],"source":["%%capture\n","from langchain.embeddings import HuggingFaceInstructEmbeddings\n","\n","instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n","                                                      model_kwargs={\"device\": \"cuda:1\"})"]},{"cell_type":"code","execution_count":null,"id":"288b1ee1-363a-484b-ba7d-c9a325b529d9","metadata":{"id":"288b1ee1-363a-484b-ba7d-c9a325b529d9","outputId":"dd5a6e31-8642-44d5-f953-222dd181884c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from tqdm.autonotebook import trange\n"]},{"name":"stdout","output_type":"stream","text":["load INSTRUCTOR_Transformer\n","max_seq_length  512\n"]}],"source":["from InstructorEmbedding import INSTRUCTOR\n","model = INSTRUCTOR('hkunlp/instructor-xl')"]},{"cell_type":"code","execution_count":null,"id":"6c787c08-d08d-4f40-9f1c-eb5b4c60fe1d","metadata":{"id":"6c787c08-d08d-4f40-9f1c-eb5b4c60fe1d","outputId":"cd4c4b6e-cda2-4644-b0f4-4d2d40598fc8"},"outputs":[{"name":"stdout","output_type":"stream","text":["S1-S2: 88%\n","S1-T: 69%\n","S2-T: 70%\n","------------------------------------\n","S1-S2: 99%\n","S1-T: 83%\n","S2-T: 83%\n","------------------------------------\n","S1-S2: 75%\n","S1-T: 71%\n","S2-T: 78%\n","------------------------------------\n","S1-S2: 80%\n","S1-T: 80%\n","S2-T: 81%\n","------------------------------------\n"]}],"source":["from scipy import spatial\n","\n","for i in (0,3,6,9):\n","  s1 = model.encode([data.iloc[i][\"sentence\"]])\n","  s2 = model.encode([data.iloc[i+1][\"sentence\"]])\n","  t = model.encode([data.iloc[i+2][\"sentence\"]])\n","  sim = 1 - spatial.distance.cosine(s1[0],s2[0])\n","  print(f\"S1-S2: {round(sim*100)}%\")\n","  sim = 1 - spatial.distance.cosine(s1[0],t[0])\n","  print(f\"S1-T: {round(sim*100)}%\")\n","  sim = 1 - spatial.distance.cosine(s2[0],t[0])\n","  print(f\"S2-T: {round(sim*100)}%\")\n","  print(\"------------------------------------\")"]},{"cell_type":"code","execution_count":null,"id":"7d09d10b-42b7-4c23-b8fb-56ea1b918031","metadata":{"jupyter":{"source_hidden":true},"id":"7d09d10b-42b7-4c23-b8fb-56ea1b918031"},"outputs":[],"source":["# Uso db pre-esistente\n","from langchain.vectorstores import Chroma\n","db = Chroma.from_documents(docs, embedding_function=instructor_embeddings)\n","\n","# il retriever \"di base\" mi ritorna 12 contesti, questi verranno poi filtrati (vedi sotto)\n","retriever = db.as_retriever(search_kwargs={\"k\": 12}, search_type=\"similarity\")"]},{"cell_type":"code","execution_count":null,"id":"f22e3ccb-11f3-4ac7-909b-efba144dde18","metadata":{"jupyter":{"source_hidden":true},"id":"f22e3ccb-11f3-4ac7-909b-efba144dde18"},"outputs":[],"source":["# Contextual Compression Retriever accetta diversi tipi di \"compressori\" che vanno\n","# a filtrare i contesti ritornati dal base retriever. Uno di questi compressori è EmbeddingsFilter\n","# che definisce una similarity threshold: i contesti non abbastanza simili alla query vengono scartati\n","\n","from langchain.retrievers import ContextualCompressionRetriever\n","from langchain.retrievers.document_compressors import EmbeddingsFilter\n","\n","SOGLIA = 0.80\n","embeddings_filter = EmbeddingsFilter(embeddings=instructor_embeddings,\n","                                     similarity_threshold=SOGLIA)\n","compression_retriever = ContextualCompressionRetriever(base_compressor=embeddings_filter,\n","                                                       base_retriever=retriever)"]},{"cell_type":"code","execution_count":null,"id":"0f250743-346a-4c86-b63c-c62b5953cedb","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"id":"0f250743-346a-4c86-b63c-c62b5953cedb","outputId":"518640f4-8c95-4408-acd0-983b13062180"},"outputs":[{"name":"stdout","output_type":"stream","text":["Query Riga: 1\n","Righe ritornate: [1, 2] \n","\n","Query Riga: 2\n","Righe ritornate: [1, 2] \n","\n","Query Riga: 3\n","Righe ritornate: [3, 9] \n","\n","Query Riga: 4\n","Righe ritornate: [4, 5, 6] \n","\n","Query Riga: 5\n","Righe ritornate: [4, 5, 6] \n","\n","Query Riga: 6\n","Righe ritornate: [4, 5, 6] \n","\n","Query Riga: 7\n","Righe ritornate: [7] \n","\n","Query Riga: 8\n","Righe ritornate: [8] \n","\n","Query Riga: 9\n","Righe ritornate: [3, 9] \n","\n","Query Riga: 10\n","Righe ritornate: [10] \n","\n","Query Riga: 11\n","Righe ritornate: [11, 12] \n","\n","Query Riga: 12\n","Righe ritornate: [11, 12] \n","\n"]}],"source":["for index, row in data.iterrows():\n","    query = data.iloc[index][\"sentence\"]\n","    result = compression_retriever.get_relevant_documents(query)\n","    result_rows = sorted([r.metadata[\"row\"] for r in result])\n","    print(f\"Query Riga: {index+1}\")\n","    print(f\"Righe ritornate: {result_rows} \\n\")"]},{"cell_type":"markdown","id":"a8077f80-72a9-4f32-bd54-6cab735add0c","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"a8077f80-72a9-4f32-bd54-6cab735add0c"},"source":["## OpenAI Embeddings"]},{"cell_type":"code","execution_count":null,"id":"38cfa3b6-6b5a-4925-8bc8-8538a807435b","metadata":{"id":"38cfa3b6-6b5a-4925-8bc8-8538a807435b"},"outputs":[],"source":["from langchain.embeddings import OpenAIEmbeddings\n","\n","openai_doc = OpenAIEmbeddings(openai_api_key=\"\",\n","                                   model = \"text-search-davinci-doc-001\")\n","openai_query = OpenAIEmbeddings(openai_api_key=\"\",\n","                                   model = \"text-search-davinci-query-001\")\n","openaiEmb = OpenAIEmbeddings(openai_api_key=\"\")"]},{"cell_type":"code","execution_count":null,"id":"1d970e1e-fcbf-4847-8a33-c087c3cb8315","metadata":{"id":"1d970e1e-fcbf-4847-8a33-c087c3cb8315"},"outputs":[],"source":["# Uso db pre-esistente\n","from langchain.vectorstores import Chroma\n","db = Chroma.from_documents(docs,embedding=openai_doc)\n","retriever = db.as_retriever(search_kwargs={\"k\": 12}, search_type=\"similarity\")"]},{"cell_type":"code","execution_count":null,"id":"2eba6a2e-5d2b-44a9-9065-ca46ef13d42f","metadata":{"id":"2eba6a2e-5d2b-44a9-9065-ca46ef13d42f"},"outputs":[],"source":["# Similarity Threshold\n","from langchain.retrievers import ContextualCompressionRetriever\n","from langchain.retrievers.document_compressors import EmbeddingsFilter\n","\n","SOGLIA = 0.99\n","embeddings_filter_OpenAI = EmbeddingsFilter(embeddings=openai_doc, similarity_threshold=SOGLIA)\n","compression_retriever_OpenAI = ContextualCompressionRetriever(base_compressor=embeddings_filter_OpenAI,\n","                                                              base_retriever=retriever)"]},{"cell_type":"code","execution_count":null,"id":"efef8be6-19ee-4acc-a742-1f9000feac7e","metadata":{"id":"efef8be6-19ee-4acc-a742-1f9000feac7e","outputId":"ccc5cc3a-b88a-486a-a86d-82838a30015f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-ZvZrqo2NGOFgLzOcyhl12uiy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n","Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-ZvZrqo2NGOFgLzOcyhl12uiy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"]},{"name":"stdout","output_type":"stream","text":["Righe ritornate: [] \n","\n"]}],"source":["#for index, row in data.iterrows():\n","query = data.iloc[0][\"sentence\"]\n","result = compression_retriever_OpenAI.get_relevant_documents(query)\n","result_rows = sorted([r.metadata[\"row\"] for r in result])\n","#print(f\"Query Riga: {index+1}\")\n","print(f\"Righe ritornate: {result_rows} \\n\")"]},{"cell_type":"code","execution_count":null,"id":"f0c9f7ba-902a-4606-9b54-f118311cda58","metadata":{"id":"f0c9f7ba-902a-4606-9b54-f118311cda58","outputId":"5d9d6738-8843-4ae0-a06d-1e6213813a4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Riga: 7 con similarity 0.5228797197341919\n","Riga: 11 con similarity 0.5262295007705688\n","Riga: 1 con similarity 0.5331012606620789\n","Riga: 12 con similarity 0.541365385055542\n"]}],"source":["vector=openai_query.embed_query(data.iloc[11][\"sentence\"])\n","res = db.similarity_search_by_vector_with_relevance_scores(vector, kwargs={'score_threshold':SOGLIA})\n","for r in res:\n","    print(f\"Riga: {r[0].metadata['row']} con similarity {r[1]}\")"]},{"cell_type":"markdown","id":"e0ad5116-9625-4469-a3f7-5c635a8f9e53","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"e0ad5116-9625-4469-a3f7-5c635a8f9e53"},"source":["## E5-Large-V2"]},{"cell_type":"code","execution_count":null,"id":"fd47fc54-b5b3-43e8-b7d0-9a9d0b4c613c","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"fd47fc54-b5b3-43e8-b7d0-9a9d0b4c613c","outputId":"d5785a50-4027-465b-ecb6-1839c3db6bd3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","Downloading (…)b9212/.gitattributes: 100%|██████████| 1.48k/1.48k [00:00<00:00, 12.1MB/s]\n","Downloading (…)_Pooling/config.json: 100%|██████████| 201/201 [00:00<00:00, 2.05MB/s]\n","Downloading (…)0777bb9212/README.md: 100%|██████████| 67.5k/67.5k [00:00<00:00, 16.6MB/s]\n","Downloading (…)77bb9212/config.json: 100%|██████████| 616/616 [00:00<00:00, 6.21MB/s]\n","Downloading (…)777bb9212/handler.py: 100%|██████████| 1.12k/1.12k [00:00<00:00, 11.3MB/s]\n","Downloading model.safetensors: 100%|██████████| 1.34G/1.34G [02:02<00:00, 10.9MB/s]\n","Downloading pytorch_model.bin: 100%|██████████| 1.34G/1.34G [02:01<00:00, 11.0MB/s]\n","Downloading (…)nce_bert_config.json: 100%|██████████| 57.0/57.0 [00:00<00:00, 541kB/s]\n","Downloading (…)cial_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 1.26MB/s]\n","Downloading (…)b9212/tokenizer.json: 100%|██████████| 711k/711k [00:00<00:00, 1.74MB/s]\n","Downloading (…)okenizer_config.json: 100%|██████████| 314/314 [00:00<00:00, 3.17MB/s]\n","Downloading (…)0777bb9212/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 2.33MB/s]\n","Downloading (…)7bb9212/modules.json: 100%|██████████| 387/387 [00:00<00:00, 3.84MB/s]\n"]}],"source":["from langchain.embeddings import HuggingFaceEmbeddings\n","\n","model_name = \"intfloat/e5-large-v2\"\n","model_kwargs = {'device': 'cuda:0'}\n","encode_kwargs = {'normalize_embeddings': False}\n","e5 = HuggingFaceEmbeddings(\n","    model_name=model_name,\n","    model_kwargs=model_kwargs,\n","    encode_kwargs=encode_kwargs\n",")"]},{"cell_type":"code","execution_count":null,"id":"b7c5dd7f-813e-4679-8527-ea69e279a56d","metadata":{"id":"b7c5dd7f-813e-4679-8527-ea69e279a56d"},"outputs":[],"source":["# Uso db pre-esistente\n","from langchain.vectorstores import Chroma\n","db = Chroma.from_documents(docs, embedding=e5)\n","retriever = db.as_retriever(search_kwargs={\"k\": 12}, search_type=\"similarity\")"]},{"cell_type":"code","execution_count":null,"id":"e091084a-9f2a-4fbf-b6d6-8f9bfdbd2573","metadata":{"id":"e091084a-9f2a-4fbf-b6d6-8f9bfdbd2573"},"outputs":[],"source":["# Similarity Threshold\n","from langchain.retrievers import ContextualCompressionRetriever\n","from langchain.retrievers.document_compressors import EmbeddingsFilter\n","\n","SOGLIA = 0.832\n","embeddings_filter_e5 = EmbeddingsFilter(embeddings=e5, similarity_threshold=SOGLIA)\n","compression_retriever_e5 = ContextualCompressionRetriever(base_compressor=embeddings_filter_e5,\n","                                                          base_retriever=retriever)"]},{"cell_type":"code","execution_count":null,"id":"51cfa956-afe4-4ce6-af5f-958a933444a3","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"51cfa956-afe4-4ce6-af5f-958a933444a3","outputId":"d9073b9c-bba2-48c7-abe0-475ecc8f61f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Query Riga: 1\n","Righe ritornate: [1, 2, 4, 5] \n","\n","Query Riga: 2\n","Righe ritornate: [1, 2, 4, 5, 6] \n","\n","Query Riga: 3\n","Righe ritornate: [3, 9] \n","\n","Query Riga: 4\n","Righe ritornate: [1, 2, 4, 5, 6] \n","\n","Query Riga: 5\n","Righe ritornate: [1, 2, 4, 5, 6, 7] \n","\n","Query Riga: 6\n","Righe ritornate: [2, 4, 5, 6] \n","\n","Query Riga: 7\n","Righe ritornate: [5, 7] \n","\n","Query Riga: 8\n","Righe ritornate: [8] \n","\n","Query Riga: 9\n","Righe ritornate: [3, 9, 12] \n","\n","Query Riga: 10\n","Righe ritornate: [10, 11, 12] \n","\n","Query Riga: 11\n","Righe ritornate: [10, 11, 12] \n","\n","Query Riga: 12\n","Righe ritornate: [9, 10, 11, 12] \n","\n"]}],"source":["for index, row in data.iterrows():\n","    query = data.iloc[index][\"sentence\"]\n","    result = compression_retriever_e5.get_relevant_documents(query)\n","    result_rows = sorted([r.metadata[\"row\"] for r in result])\n","    print(f\"Query Riga: {index+1}\")\n","    print(f\"Righe ritornate: {result_rows} \\n\")"]},{"cell_type":"code","execution_count":null,"id":"a0c29700-3b88-449b-8490-be77b99f51f8","metadata":{"id":"a0c29700-3b88-449b-8490-be77b99f51f8"},"outputs":[],"source":["query = data.iloc[0][\"sentence\"]\n","result = db.similarity_search_with_relevance_scores(query, k=12)\n","result_rows = sorted([r.metadata[\"row\"] for r in result])\n","print(f\"Query Riga: {index+1}\")\n","print(f\"Righe ritornate: {result_rows} \\n\")"]},{"cell_type":"code","execution_count":null,"id":"ccbbc1a4-f8a2-4be1-8fc9-0d15a813e601","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"ccbbc1a4-f8a2-4be1-8fc9-0d15a813e601","outputId":"25dd7cfe-e718-45b4-c751-ba2e5a7a268f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Riga: 1\n","score: 0.9999999999991269 \n"," -------\n","Riga: 2\n","score: 0.8566821809863276 \n"," -------\n","Riga: 5\n","score: 0.7689114848662242 \n"," -------\n","Riga: 4\n","score: 0.7651595513383602 \n"," -------\n","Riga: 6\n","score: 0.7543052627071071 \n"," -------\n","Riga: 7\n","score: 0.7441451537442527 \n"," -------\n","Riga: 10\n","score: 0.721535097538947 \n"," -------\n","Riga: 9\n","score: 0.7144739620534015 \n"," -------\n","Riga: 12\n","score: 0.7132661387422006 \n"," -------\n","Riga: 8\n","score: 0.7023009406790911 \n"," -------\n","Riga: 3\n","score: 0.6953162806501687 \n"," -------\n","Riga: 11\n","score: 0.6941541234493294 \n"," -------\n"]}],"source":["for r in result:\n","    print(f\"Riga: {r[0].metadata['row']}\")\n","    print(f\"score: {r[1]} \\n -------\")"]},{"cell_type":"markdown","id":"9baf49cb-069c-4bd5-b13b-0f48508e2278","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"9baf49cb-069c-4bd5-b13b-0f48508e2278"},"source":["## all-MPNET-base-v2"]},{"cell_type":"code","execution_count":null,"id":"b1ccf68a-ac39-4c55-8bcb-cec030c95b44","metadata":{"id":"b1ccf68a-ac39-4c55-8bcb-cec030c95b44"},"outputs":[],"source":["from langchain.embeddings import HuggingFaceEmbeddings\n","\n","model_name = \"sentence-transformers/all-mpnet-base-v2\"\n","model_kwargs = {'device': 'cuda:1'}\n","encode_kwargs = {'normalize_embeddings': False}\n","mptNet = HuggingFaceEmbeddings(\n","    model_name=model_name,\n","    model_kwargs=model_kwargs,\n","    encode_kwargs=encode_kwargs\n",")"]},{"cell_type":"code","execution_count":null,"id":"78a0cabf-5153-4ff2-bc47-4b0c9295c06a","metadata":{"id":"78a0cabf-5153-4ff2-bc47-4b0c9295c06a"},"outputs":[],"source":["# Uso db pre-esistente\n","from langchain.vectorstores import Chroma\n","db = Chroma.from_documents(docs, embedding=mptNet)\n","retriever = db.as_retriever(search_kwargs={\"k\": 12}, search_type=\"similarity\")"]},{"cell_type":"code","execution_count":null,"id":"e17e4e07-1b28-4726-86cc-abadc12c6e63","metadata":{"id":"e17e4e07-1b28-4726-86cc-abadc12c6e63"},"outputs":[],"source":["# Similarity Threshold\n","from langchain.retrievers import ContextualCompressionRetriever\n","from langchain.retrievers.document_compressors import EmbeddingsFilter\n","\n","SOGLIA = 0.57\n","embeddings_filter_mptNet= EmbeddingsFilter(embeddings=mptNet, similarity_threshold=SOGLIA)\n","compression_retriever_mptNet = ContextualCompressionRetriever(base_compressor=embeddings_filter_mptNet,\n","                                                          base_retriever=retriever)"]},{"cell_type":"code","execution_count":null,"id":"10bdd207-427b-49b5-8f96-3eaedfe943ab","metadata":{"id":"10bdd207-427b-49b5-8f96-3eaedfe943ab","outputId":"1350a8bc-555d-4f61-b63d-e070b6fe6a63"},"outputs":[{"name":"stdout","output_type":"stream","text":["Query Riga: 1\n","Righe ritornate: [1, 2] \n","\n","Query Riga: 2\n","Righe ritornate: [1, 2] \n","\n","Query Riga: 3\n","Righe ritornate: [3, 6, 9] \n","\n","Query Riga: 4\n","Righe ritornate: [4, 5, 6] \n","\n","Query Riga: 5\n","Righe ritornate: [4, 5, 6] \n","\n","Query Riga: 6\n","Righe ritornate: [3, 4, 5, 6, 9] \n","\n","Query Riga: 7\n","Righe ritornate: [7] \n","\n","Query Riga: 8\n","Righe ritornate: [8] \n","\n","Query Riga: 9\n","Righe ritornate: [3, 6, 9] \n","\n","Query Riga: 10\n","Righe ritornate: [10, 11] \n","\n","Query Riga: 11\n","Righe ritornate: [10, 11] \n","\n","Query Riga: 12\n","Righe ritornate: [12] \n","\n"]}],"source":["for index, row in data.iterrows():\n","    query = data.iloc[index][\"sentence\"]\n","    result = compression_retriever_mptNet.get_relevant_documents(query)\n","    result_rows = sorted([r.metadata[\"row\"] for r in result])\n","    print(f\"Query Riga: {index+1}\")\n","    print(f\"Righe ritornate: {result_rows} \\n\")"]},{"cell_type":"markdown","id":"d6fb0e4b-8886-48fa-bb89-a13f1596d07b","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"d6fb0e4b-8886-48fa-bb89-a13f1596d07b"},"source":["## all-MiniLM-L12-v2"]},{"cell_type":"code","execution_count":null,"id":"7cfba6c4-4f89-491a-86a5-7b69dcd81c5d","metadata":{"id":"7cfba6c4-4f89-491a-86a5-7b69dcd81c5d","outputId":"e378a369-b167-4986-8461-81637787acf7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading (…)5dded/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 13.0MB/s]\n","Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 2.50MB/s]\n","Downloading (…)4d81d5dded/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 84.9MB/s]\n","Downloading (…)81d5dded/config.json: 100%|██████████| 573/573 [00:00<00:00, 7.44MB/s]\n","Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 1.56MB/s]\n","Downloading (…)ded/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 394kB/s]\n","Downloading pytorch_model.bin: 100%|██████████| 134M/134M [00:11<00:00, 11.2MB/s] \n","Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 553kB/s]\n","Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 1.25MB/s]\n","Downloading (…)5dded/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.48MB/s]\n","Downloading (…)okenizer_config.json: 100%|██████████| 352/352 [00:00<00:00, 3.41MB/s]\n","Downloading (…)dded/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 95.8MB/s]\n","Downloading (…)4d81d5dded/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 12.6MB/s]\n","Downloading (…)1d5dded/modules.json: 100%|██████████| 349/349 [00:00<00:00, 3.39MB/s]\n"]}],"source":["from langchain.embeddings import HuggingFaceEmbeddings\n","\n","model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n","model_kwargs = {'device': 'cuda:1'}\n","encode_kwargs = {'normalize_embeddings': False}\n","miniLM = HuggingFaceEmbeddings(\n","    model_name=model_name,\n","    model_kwargs=model_kwargs,\n","    encode_kwargs=encode_kwargs\n",")"]},{"cell_type":"code","execution_count":null,"id":"9872eabf-ba3f-4eec-a433-b497f363334b","metadata":{"id":"9872eabf-ba3f-4eec-a433-b497f363334b"},"outputs":[],"source":["from langchain.vectorstores import Chroma\n","db = Chroma.from_documents(docs, embedding=miniLM)\n","retriever = db.as_retriever(search_kwargs={\"k\": 12}, search_type=\"similarity\")"]},{"cell_type":"code","execution_count":null,"id":"141446f4-39fd-4e44-be06-a9462f17649d","metadata":{"id":"141446f4-39fd-4e44-be06-a9462f17649d"},"outputs":[],"source":["# Similarity Threshold\n","from langchain.retrievers import ContextualCompressionRetriever\n","from langchain.retrievers.document_compressors import EmbeddingsFilter\n","\n","SOGLIA = 0.50\n","embeddings_filter_miniLM = EmbeddingsFilter(embeddings=miniLM, similarity_threshold=SOGLIA)\n","compression_retriever_miniLM = ContextualCompressionRetriever(base_compressor=embeddings_filter_miniLM,\n","                                                          base_retriever=retriever)"]},{"cell_type":"code","execution_count":null,"id":"a5016549-f6dc-4d5a-850f-c2c448c0a260","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"a5016549-f6dc-4d5a-850f-c2c448c0a260","outputId":"cd56a040-62b8-426c-f487-11d007c5645c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Query Riga: 1\n","Righe ritornate: [1, 2] \n","\n","Query Riga: 2\n","Righe ritornate: [1, 2] \n","\n","Query Riga: 3\n","Righe ritornate: [3, 6, 9] \n","\n","Query Riga: 4\n","Righe ritornate: [4, 5, 6] \n","\n","Query Riga: 5\n","Righe ritornate: [4, 5, 6] \n","\n","Query Riga: 6\n","Righe ritornate: [3, 4, 5, 6] \n","\n","Query Riga: 7\n","Righe ritornate: [7] \n","\n","Query Riga: 8\n","Righe ritornate: [8] \n","\n","Query Riga: 9\n","Righe ritornate: [3, 9] \n","\n","Query Riga: 10\n","Righe ritornate: [10, 11, 12] \n","\n","Query Riga: 11\n","Righe ritornate: [10, 11, 12] \n","\n","Query Riga: 12\n","Righe ritornate: [10, 11, 12] \n","\n"]}],"source":["for index, row in data.iterrows():\n","    query = data.iloc[index][\"sentence\"]\n","    result = compression_retriever_miniLM.get_relevant_documents(query)\n","    result_rows = sorted([r.metadata[\"row\"] for r in result])\n","    print(f\"Query Riga: {index+1}\")\n","    print(f\"Righe ritornate: {result_rows} \\n\")"]},{"cell_type":"markdown","id":"3ba5335b-7c2b-410b-b89e-c842fb4b56b0","metadata":{"id":"3ba5335b-7c2b-410b-b89e-c842fb4b56b0"},"source":["## GTE-Large"]},{"cell_type":"code","execution_count":null,"id":"6a552509-78f5-4816-b960-ffe3b1d1df7d","metadata":{"id":"6a552509-78f5-4816-b960-ffe3b1d1df7d","outputId":"2ca8aa19-cacc-4dd7-e2b6-db9e1fb0df01"},"outputs":[{"name":"stderr","output_type":"stream","text":["No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/thenlper_gte-large. Creating a new one with MEAN pooling.\n"]}],"source":["from langchain.embeddings import HuggingFaceEmbeddings\n","\n","model_name = \"thenlper/gte-large\"\n","model_kwargs = {'device': 'cuda:1'}\n","encode_kwargs = {'normalize_embeddings': False}\n","gte = HuggingFaceEmbeddings(\n","    model_name=model_name,\n","    model_kwargs=model_kwargs,\n","    encode_kwargs=encode_kwargs\n",")"]},{"cell_type":"code","execution_count":null,"id":"0bced469-9923-4f00-810f-08a9ed8bf2ce","metadata":{"id":"0bced469-9923-4f00-810f-08a9ed8bf2ce"},"outputs":[],"source":["from langchain.vectorstores import Chroma\n","db = Chroma.from_documents(docs, embedding=gte)\n","retriever = db.as_retriever(search_kwargs={\"k\": 12}, search_type=\"similarity\")"]},{"cell_type":"code","execution_count":null,"id":"f2a5345d-96da-497a-b270-78611c3b7681","metadata":{"id":"f2a5345d-96da-497a-b270-78611c3b7681"},"outputs":[],"source":["# Similarity Threshold\n","from langchain.retrievers import ContextualCompressionRetriever\n","from langchain.retrievers.document_compressors import EmbeddingsFilter\n","\n","SOGLIA = 0.87\n","embeddings_filter_gte = EmbeddingsFilter(embeddings=gte, similarity_threshold=SOGLIA)\n","compression_retriever_gte = ContextualCompressionRetriever(base_compressor=embeddings_filter_gte,\n","                                                          base_retriever=retriever)"]},{"cell_type":"code","execution_count":null,"id":"057f3e03-2e5c-4290-b39f-c04bbf477915","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"057f3e03-2e5c-4290-b39f-c04bbf477915","outputId":"cbbc810f-c9d3-49dc-dba6-08e70e0cc22b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Query Riga: 1\n","Righe ritornate: [1, 2] \n","\n","Query Riga: 2\n","Righe ritornate: [1, 2, 8] \n","\n","Query Riga: 3\n","Righe ritornate: [3, 6, 9] \n","\n","Query Riga: 4\n","Righe ritornate: [4, 5, 6] \n","\n","Query Riga: 5\n","Righe ritornate: [4, 5, 6] \n","\n","Query Riga: 6\n","Righe ritornate: [3, 4, 5, 6, 9] \n","\n","Query Riga: 7\n","Righe ritornate: [7] \n","\n","Query Riga: 8\n","Righe ritornate: [2, 8, 9] \n","\n","Query Riga: 9\n","Righe ritornate: [3, 6, 8, 9] \n","\n","Query Riga: 10\n","Righe ritornate: [10, 11, 12] \n","\n","Query Riga: 11\n","Righe ritornate: [10, 11, 12] \n","\n","Query Riga: 12\n","Righe ritornate: [10, 11, 12] \n","\n"]}],"source":["for index, row in data.iterrows():\n","    query = data.iloc[index][\"sentence\"]\n","    result = compression_retriever_gte.get_relevant_documents(query)\n","    result_rows = sorted([r.metadata[\"row\"] for r in result])\n","    print(f\"Query Riga: {index+1}\")\n","    print(f\"Righe ritornate: {result_rows} \\n\")"]},{"cell_type":"code","execution_count":null,"id":"bcb3b854-7a06-4c74-b33c-e13d29ae18db","metadata":{"id":"bcb3b854-7a06-4c74-b33c-e13d29ae18db","outputId":"5e2eefbd-09e4-4386-ec8f-bfac66b1db44"},"outputs":[{"ename":"TypeError","evalue":"HuggingFaceEmbeddings.embed_documents() got an unexpected keyword argument 'convert_to_tensor'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[0;32m----> 2\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mgte\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m B \u001b[38;5;241m=\u001b[39m gte\u001b[38;5;241m.\u001b[39membed_documents(data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m], convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m util\u001b[38;5;241m.\u001b[39mpytorch_cos_sim(A,B)\n","\u001b[0;31mTypeError\u001b[0m: HuggingFaceEmbeddings.embed_documents() got an unexpected keyword argument 'convert_to_tensor'"]}],"source":["from sentence_transformers import util\n","A = gte.embed_documents(data.iloc[1][\"sentence\"], convert_to_tensor=True)\n","B = gte.embed_documents(data.iloc[2][\"sentence\"], convert_to_tensor=True)\n","\n","util.pytorch_cos_sim(A,B)"]},{"cell_type":"code","execution_count":null,"id":"46e43780-c498-4c55-864b-718d18203971","metadata":{"id":"46e43780-c498-4c55-864b-718d18203971","outputId":"306546d4-7aef-4170-9f65-466eafab1510"},"outputs":[{"name":"stdout","output_type":"stream","text":["S1-TARGET: 0.8230722291311259\n","S2-TARGET: 0.8461697329265342\n","S1-S2: 0.9155346744881976 \n"," -----------------------------\n","S1-TARGET: 0.9155068380743657\n","S2-TARGET: 0.9105818033904317\n","S1-S2: 0.9968708839028425 \n"," -----------------------------\n","S1-TARGET: 0.8223792497763691\n","S2-TARGET: 0.8752487659117552\n","S1-S2: 0.8448056204368667 \n"," -----------------------------\n","S1-TARGET: 0.8758212720703982\n","S2-TARGET: 0.8784227767909063\n","S1-S2: 0.9021518479642557 \n"," -----------------------------\n"]}],"source":["from langchain.evaluation import EmbeddingDistanceEvalChain\n","\n","chain = EmbeddingDistanceEvalChain(embeddings = gte)\n","\n","for i in (0,3,6,9):\n","    s1 = data.iloc[i][\"sentence\"]\n","    s2 = data.iloc[i+1][\"sentence\"]\n","    t = data.iloc[i+2][\"sentence\"]\n","    distance = chain.evaluate_strings(prediction=s1, reference=t)\n","    print(f\"S1-TARGET: {1-distance['score']}\")\n","    distance = chain.evaluate_strings(prediction=s2, reference=t)\n","    print(f\"S2-TARGET: {1-distance['score']}\")\n","    distance = chain.evaluate_strings(prediction=s1, reference=s2)\n","    print(f\"S1-S2: {1-distance['score']} \\n -----------------------------\")"]},{"cell_type":"markdown","id":"efd3b3a9-4dee-4df1-ba17-b06cfdb584f5","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"efd3b3a9-4dee-4df1-ba17-b06cfdb584f5"},"source":["## **LLM Compressor**"]},{"cell_type":"markdown","source":["Un altro modo per filtrare i contesti ritornati dal base retriever è usare un LLM che li legge insieme alla query e scarta quelli che non considera rilevanti"],"metadata":{"id":"XP9vSucFf6Zk"},"id":"XP9vSucFf6Zk"},{"cell_type":"code","execution_count":null,"id":"b344c836-d0e7-411b-a22e-4c1fa0cba0c8","metadata":{"id":"b344c836-d0e7-411b-a22e-4c1fa0cba0c8"},"outputs":[],"source":["from langchain.retrievers import ContextualCompressionRetriever\n","from langchain.retrievers.document_compressors import LLMChainFilter\n","\n","retriever = db.as_retriever(search_kwargs={\"k\": 5}, search_type=\"similarity\")\n","\n","compressor = LLMChainFilter.from_llm(local_llm,\n","                                     #prompt=myPrompt,\n","                                     )\n","\n","compression_retriever = ContextualCompressionRetriever(base_compressor=compressor,\n","                                                       base_retriever=retriever)"]},{"cell_type":"code","execution_count":null,"id":"5e4c2538-5204-4157-903b-dfc7b30c6090","metadata":{"id":"5e4c2538-5204-4157-903b-dfc7b30c6090"},"outputs":[],"source":["# Posso definire un custom prompt per l'LLM che fungerà da filtro, utile\n","# per fornirgli documentazione extra riguardo il contesto in cui lavora\n","\n","myTemplate = \"\"\"\n","Given the following question and context, return YES if the context is STRICTLY relevant to the question and NO if it isn't.\n","\n","> Question: {question}\n","> Context: {context}\n","> Is the context relevant? answer:\n","\"\"\"\n","from langchain.prompts import PromptTemplate\n","\n","myPrompt = PromptTemplate(template=myTemplate, input_variables=[\"context\", \"question\"])"]},{"cell_type":"code","source":["# Posso usarlo direttamente come retriever e basta\n","compression_retriever.get_relevant_documents(\"query\")\n","\n","# Oppure inserirlo all'interno di una QA chain con vector db al posto del solito base retriever"],"metadata":{"id":"_cQH9MJtgxrT"},"id":"_cQH9MJtgxrT","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[],"collapsed_sections":["a8077f80-72a9-4f32-bd54-6cab735add0c","e0ad5116-9625-4469-a3f7-5c635a8f9e53","9baf49cb-069c-4bd5-b13b-0f48508e2278","d6fb0e4b-8886-48fa-bb89-a13f1596d07b","3ba5335b-7c2b-410b-b89e-c842fb4b56b0"]}},"nbformat":4,"nbformat_minor":5}